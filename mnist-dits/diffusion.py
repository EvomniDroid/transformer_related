"""
æ‰©æ•£è¿‡ç¨‹ (Diffusion Process) å®ç°

æ‰©æ•£æ¨¡å‹çš„æ ¸å¿ƒï¼š
1. å‰å‘è¿‡ç¨‹ï¼ˆForwardï¼‰ï¼šé€æ­¥å‘å›¾åƒæ·»åŠ å™ªå£°ï¼Œç›´åˆ°å˜æˆçº¯å™ªå£°
2. åå‘è¿‡ç¨‹ï¼ˆReverseï¼‰ï¼šè®­ç»ƒæ¨¡å‹å­¦ä¹ å»å™ªï¼Œä»å™ªå£°è¿˜åŸå›¾åƒ

æ•°å­¦åŸç†ï¼š
- å‰å‘æ‰©æ•£ï¼šq(x_t | x_0) = N(x_t; sqrt(alpha_cumprod_t) * x_0, (1 - alpha_cumprod_t) * I)
- å³ï¼šx_t = sqrt(alpha_cumprod_t) * x_0 + sqrt(1 - alpha_cumprod_t) * noise

å…¶ä¸­ï¼š
- x_0: åŸå§‹æ¸…æ™°å›¾åƒ
- x_t: t æ—¶åˆ»çš„å¸¦å™ªå›¾åƒ
- noise: æ ‡å‡†é«˜æ–¯å™ªå£° N(0, I)
- alpha_t = 1 - beta_t
- alpha_cumprod_t = alpha_1 * alpha_2 * ... * alpha_t
"""

import os
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'  # è§£å†³ OpenMP åº“å†²çª

import torch 
from config import T

# ===== å™ªå£°è°ƒåº¦å‚æ•° =====
# Beta: æ§åˆ¶æ¯ä¸€æ­¥æ·»åŠ å¤šå°‘å™ªå£°
# beta_t ä» 0.0001 é€æ¸å¢åŠ åˆ° 0.02
# - æ—©æœŸï¼ˆtå°ï¼‰: beta å°ï¼ŒåŠ å™ªæ…¢ï¼Œä¿ç•™æ›´å¤šåŸå›¾ä¿¡æ¯
# - åæœŸï¼ˆtå¤§ï¼‰: beta å¤§ï¼ŒåŠ å™ªå¿«ï¼Œå¿«é€Ÿå˜æˆçº¯å™ªå£°
betas = torch.linspace(0.0001, 0.02, T)  # shape: (T,)

# Alpha: alpha_t = 1 - beta_t
# è¡¨ç¤ºä¿ç•™åŸå›¾çš„æ¯”ä¾‹
alphas = 1 - betas  # shape: (T,)

# Alpha ç´¯ç§¯ä¹˜ç§¯: alpha_cumprod_t = alpha_1 * alpha_2 * ... * alpha_t
# è¿™æ˜¯ä» x_0 ç›´æ¥è·³åˆ° x_t çš„å…³é”®å‚æ•°
# ä¾‹å¦‚ï¼šalpha_cumprod[100] è¡¨ç¤ºä»åŸå›¾ä¸€æ­¥è·³åˆ°ç¬¬ 100 æ­¥çš„è¡°å‡ç³»æ•°
alphas_cumprod = torch.cumprod(alphas, dim=-1)  # shape: (T,)
# [a_1, a_1*a_2, a_1*a_2*a_3, ...]

# Alpha ç´¯ç§¯ä¹˜ç§¯ï¼ˆå‰ä¸€æ­¥ï¼‰
# ç”¨äºåå‘å»å™ªæ—¶çš„æ–¹å·®è®¡ç®—
alphas_cumprod_prev = torch.cat((torch.tensor([1.0]), alphas_cumprod[:-1]), dim=-1)
# shape: (T,)
# [1, a_1, a_1*a_2, a_1*a_2*a_3, ...]

# åå‘å»å™ªçš„æ–¹å·®
# å…¬å¼ï¼švariance_t = (1 - alpha_t) * (1 - alpha_cumprod_{t-1}) / (1 - alpha_cumprod_t)
variance = (1 - alphas) * (1 - alphas_cumprod_prev) / (1 - alphas_cumprod)  # shape: (T,)

def forward_add_noise(x, t):
    """
    å‰å‘åŠ å™ªï¼šä¸€æ­¥åˆ°ä½åœ°ä» x_0 ç”Ÿæˆ x_t
    
    å…¬å¼ï¼šx_t = sqrt(alpha_cumprod_t) * x_0 + sqrt(1 - alpha_cumprod_t) * noise
    
    å‚æ•°ï¼š
        x: åŸå§‹å›¾åƒï¼Œshape=(batch, channel, height, width)
           å–å€¼èŒƒå›´åº”è¯¥æ˜¯ [-1, 1]ï¼ˆæ ‡å‡†åŒ–åï¼‰
        t: æ—¶é—´æ­¥ï¼Œshape=(batch,)
           ä¾‹å¦‚ï¼š[500, 200, 800, ...] - æ¯ä¸ªæ ·æœ¬çš„æ—¶é—´æ­¥å¯ä»¥ä¸åŒ
    
    è¿”å›ï¼š
        x_t: åŠ å™ªåçš„å›¾åƒï¼Œshape=(batch, channel, height, width)
        noise: æ·»åŠ çš„é«˜æ–¯å™ªå£°ï¼Œshape=(batch, channel, height, width)
    """
    
    # ç”Ÿæˆæ ‡å‡†é«˜æ–¯å™ªå£° N(0, I)
    noise = torch.randn_like(x)  # shape: (batch, channel, height, width)
    
    # æ ¹æ®æ—¶é—´æ­¥ t è·å–å¯¹åº”çš„ alpha_cumprod
    # alphas_cumprod[t] â†’ (batch,)
    # ç„¶å reshape æˆ (batch, 1, 1, 1) ç”¨äºå¹¿æ’­
    batch_alphas_cumprod = alphas_cumprod[t].view(x.size(0), 1, 1, 1)
    
    # åº”ç”¨å‰å‘æ‰©æ•£å…¬å¼
    # x_t = sqrt(alpha_cumprod) * x_0 + sqrt(1 - alpha_cumprod) * noise
    x_t = torch.sqrt(batch_alphas_cumprod) * x + torch.sqrt(1 - batch_alphas_cumprod) * noise
    
    # è¿”å›åŠ å™ªå›¾åƒå’Œå™ªå£°ï¼ˆè®­ç»ƒæ—¶éœ€è¦é¢„æµ‹è¿™ä¸ªå™ªå£°ï¼‰
    return x_t, noise

if __name__ == '__main__':
    # ===== æµ‹è¯•ä»£ç ï¼šå¯è§†åŒ–æ‰©æ•£è¿‡ç¨‹ =====
    import matplotlib.pyplot as plt 
    from dataset import MNIST
    
    print("ğŸ§ª æµ‹è¯•å‰å‘æ‰©æ•£è¿‡ç¨‹")
    
    # åŠ è½½æ•°æ®é›†
    dataset = MNIST()
    
    # è·å– 2 å¼ å›¾åƒç»„æˆ batch
    x = torch.stack((dataset[0][0], dataset[1][0]), dim=0)  # shape: (2, 1, 28, 28)
    print(f"åŸå§‹å›¾åƒ shape: {x.shape}")
    print(f"åŸå§‹å›¾åƒå–å€¼èŒƒå›´: [{x.min():.3f}, {x.max():.3f}]")

    # ===== æ˜¾ç¤ºåŸå›¾ =====
    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.imshow(x[0].permute(1, 2, 0), cmap='gray')
    plt.title("Original Image 1")
    plt.axis('off')
    plt.subplot(1, 2, 2)
    plt.imshow(x[1].permute(1, 2, 0), cmap='gray')
    plt.title("Original Image 2")
    plt.axis('off')
    plt.tight_layout()
    plt.show()

    # ===== éšæœºæ—¶é—´æ­¥ =====
    t = torch.randint(0, T, size=(x.size(0),))
    print(f'\næ—¶é—´æ­¥ t: {t}')
    
    # ===== æ ‡å‡†åŒ–åˆ° [-1, 1] =====
    # åŸå§‹å›¾åƒæ˜¯ [0, 1]ï¼Œæ‰©æ•£æ¨¡å‹é€šå¸¸ä½¿ç”¨ [-1, 1]
    x = x * 2 - 1  # [0, 1] â†’ [-1, 1]
    print(f"æ ‡å‡†åŒ–åå–å€¼èŒƒå›´: [{x.min():.3f}, {x.max():.3f}]")
    
    # ===== æ‰§è¡ŒåŠ å™ª =====
    x_noisy, noise = forward_add_noise(x, t)
    print(f'\nåŠ å™ªå›¾åƒ shape: {x_noisy.shape}')
    print(f'å™ªå£° shape: {noise.shape}')
    print(f'åŠ å™ªå›¾åƒå–å€¼èŒƒå›´: [{x_noisy.min():.3f}, {x_noisy.max():.3f}]')

    # ===== æ˜¾ç¤ºåŠ å™ªå›¾ =====
    # ä» [-1, 1] è¿˜åŸåˆ° [0, 1] ç”¨äºæ˜¾ç¤º
    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.imshow(((x_noisy[0] + 1) / 2).permute(1, 2, 0), cmap='gray')
    plt.title(f"Noisy Image 1 (t={t[0]})")
    plt.axis('off')
    plt.subplot(1, 2, 2)
    plt.imshow(((x_noisy[1] + 1) / 2).permute(1, 2, 0), cmap='gray')
    plt.title(f"Noisy Image 2 (t={t[1]})")
    plt.axis('off')
    plt.tight_layout()
    plt.show()
    
    # ===== å¯è§†åŒ–ä¸åŒæ—¶é—´æ­¥çš„åŠ å™ªæ•ˆæœ =====
    print("\nğŸ“Š ä¸åŒæ—¶é—´æ­¥çš„åŠ å™ªæ•ˆæœ:")
    test_times = [0, 100, 300, 500, 700, 900, 999]
    
    plt.figure(figsize=(14, 4))
    for i, tt in enumerate(test_times):
        t_tensor = torch.tensor([tt])
        x_test = dataset[0][0].unsqueeze(0) * 2 - 1  # (1, 1, 28, 28), [-1, 1]
        x_noisy_test, _ = forward_add_noise(x_test, t_tensor)
        
        plt.subplot(1, len(test_times), i + 1)
        plt.imshow(((x_noisy_test[0] + 1) / 2).permute(1, 2, 0), cmap='gray')
        plt.title(f"t={tt}")
        plt.axis('off')
    
    plt.suptitle("Forward Diffusion Process (ä»æ¸…æ™°åˆ°å™ªå£°)")
    plt.tight_layout()
    plt.show()
    
    print("\nâœ… æµ‹è¯•å®Œæˆï¼")
    plt.show()